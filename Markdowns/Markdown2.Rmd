---
title: "Capstone Project: ADNI Data - Markdown 2"
author: "Brian Collica, Ben Searchinger, Ryan Roggenkemper, James Koo"
date: "3/30/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Model Description

Our model consists of two stages.  Stage one tries to assess an individual's risk for Alzheimer's Disease by using fairly non-invasive clinical information which is easily accessible and low-cost.  Various simple models are considered for this stage, including models that incorporate a prediction of $\beta$-amyloid positivity for a given patient.  Research has shown that a $\beta$-amyloid positive status is highly correlated with Alzheimer's Disease, but testing for positivity is costly and invasive to the patient.  We hope to cut down on these costs by accurately predicting a patient's status using other easily accessible data, and evaluating if this technique improves Alzheimer's risk predictions.

Stage two consists of an image based classifier that utilizes MRI as well as tau PET brain scans to determine if an individual is considered cognitively normal or abnormal/AD.  The spatial arrangement of the tau protein in the brain has been a topic of recent AD research, and we hope the classifier can pick up on these subtle arrangements.  Additionally, MRI scans contain useful information regarding the level of atrophy experienced in the brain, and may help to improve overall classification rates.

The ultimate goal is to effectively sort patients which are at high risk for AD using the first stage, and then accurately classify their AD status based on their brain scans if needed.  The idea is that a patient would only receive PET/MRI scans if they are labeled as high risk for AD in the first stage.  If successful, we hope this technique can cut down on unnecessary costly procedures which are invasive and potentially harmful to the patient while also maintaining a high level of accuracy in quantifying an individual's AD status.    

We plan to evaluate our success with the following metrics:

 - First Stage True Positive, False Negative, Misclassification Rates, and Correlation with AD Diagnosis.
 
 - Second Stage Accuracy, True Positive, False Negative, & Misclassification Rates
 
 - Combined Model Accuracy, True Positive, False Negative, & Misclassification Rates
 
Ideally, we want the proportion of AD/MCI subjects among those predicted as high-risk to be higher than the proportion in the general population, assuming the ADNI sample is representative of the true older adult population.  That being said, some other metrics of interest will be the distribution of characteristics among those labeled as low-risk in the first stage, and if there is any particular information which can be used to fine tune the model.  

## First Stage Initial Fits

### Description

For the first stage model, we used the ADNIMERGE dataset available on the ADNI website.  This dataset includes many key variables of interest for each ADNI participant.  In order to determine if predicting $\beta$-amyloid assists in AD risk assessment, the dataset is filtered to include only patients who had cerebrospinal-fluid measurements taken at baseline.  Each patient's amyloid measurements were measured in a lab at the University of Pennsylvania and included in the UPENNBIOMK_MASTER dataset, also available on the ADNI website.  We combined the two datasets to get 1,087 unique baseline observations.

The two initial models are simple logistic regressions predicting the probability of AD.  One model considers the patient's sex as well as three scores from two separate cognitive tests.  The other model includes genetic information regarding the presence of 0, 1, or 2 APO$\epsilon-4$ alleles.

### Code and Output

The first stage models are fit using R and requires the following packages: `readr`, `dplyr`, `stringr`, and `origami`.  The following code reads in the data, filters by baseline visit, and renames the baseline variables of interest.

```{r, message=FALSE, warning=FALSE}
# Load Packages ####
library(readr)
library(dplyr)
library(stringr)
library(origami)

# Read Data ####
beta_tau <- read_csv("AmyloidData/beta_tau_csf_new_vars.csv")
source("cv_functions.R")

# Filter By Baseline Visit ####
baseline <- beta_tau %>%
  filter(VISCODE == "bl")

bl_na1 <- which(is.na(baseline$beta_pos) | is.na(baseline$RAVLT_immediate_bl) | 
                  is.na(baseline$Hippocampus) | is.na(baseline$WholeBrain))
bl_na2 <- which(is.na(baseline$beta_pos) | is.na(baseline$RAVLT_immediate_bl))

# Rename _bl Variables ####
bl_rm <- c(27, 54, 55)
baseline_1 <- baseline[-(bl_na1), -(bl_rm)]
baseline_1 <- rename(
  baseline_1, 
  RAVLT_immediate = RAVLT_immediate_bl,
  Hippocampus = Hippocampus_bl,
  WholeBrain = WholeBrain_bl)

baseline_2 <- baseline[-(bl_na2), -(bl_rm)]
baseline_2 <- rename(
  baseline_2, 
  RAVLT_immediate = RAVLT_immediate_bl,
  Hippocampus = Hippocampus_bl,
  WholeBrain = WholeBrain_bl)
```


The linear and logistic fits using all the baseline data can be seen below.

```{r, message=FALSE, warning=FALSE}
# Initial Model Fits ####
# Including MRI data
bl_cont <- lm(beta_csf ~ AGE + MALE + APOE4_1 + APOE4_2 + RAVLT_immediate 
              + Hippocampus + WholeBrain, 
              data = baseline_1)
bl_logit <- glm(beta_pos ~ AGE + MALE + APOE4_1 + APOE4_2 + RAVLT_immediate 
                + Hippocampus + WholeBrain, 
                data = baseline_2, family = "binomial")

# Excluding MRI Data
bl_cont2 <- lm(beta_csf ~ AGE + MALE + APOE4_1 + APOE4_2 + RAVLT_immediate, 
               data = baseline_1)
bl_logit2 <- glm(beta_pos ~ AGE + MALE + APOE4_1 + APOE4_2 + RAVLT_immediate, 
                 data = baseline_2, family = "binomial")
```


5-fold crass-validation was then run for each of the four initial baseline models.  The following code performs the cross-validation and also calculates performance metrics of interest.  The metrics calculated include:

 - Misclassification Rate: Proportion of incorrect predictions
 
 - True Positive Rate: Proportion of $\beta$-amyloid positive cases correctly classified
 
 - False Positive Rate: Proportion of $\beta$-amyloid negative cases classified as positive
 
 - True Negative Rate: Proportion of $\beta$-amyloid negative cases correctly classified
 
 - False Negative Rate: Proportion of $\beta$-amyloid positive cases classified as negative
 
 - DX Correlation: Correlation between positive prediction status and being diagnosed as AD at baseline
 
 - Positive AD: Number of subjects predicted as $\beta$-amyloid positive who were also diagnosed with AD
 
 - Negative AD: Number of subjects predicted as $\beta$-amyloid negative who were also diagnosed with AD
 
 - Percent Positive AD: Percentage of positive predictions who were also diagnosed with AD

Specific functions needed for the cross-validation and metrics calculations are defined in the `cv_functions.R` script.  

```{r, message=FALSE, warning=FALSE}
# 5-Fold Cross Validation ####
# Make Folds
bl_folds1 <- folds_vfold(nrow(baseline_1), V = 5)
bl_folds2 <- folds_vfold(nrow(baseline_2), V = 5)

# Linear Models ####
bl_cv_lm <- origami::cross_validate(
  cv_fun = cv_lm, folds = bl_folds1, data = baseline_1,
  reg_form = "beta_csf ~ AGE + MALE + APOE4_1 + APOE4_2 + RAVLT_immediate + Hippocampus + WholeBrain")

bl_cv_lm2 <- origami::cross_validate(
  cv_fun = cv_lm, folds = bl_folds2, data = baseline_2,
  reg_form = "beta_csf ~ AGE + MALE + APOE4_1 + APOE4_2 + RAVLT_immediate")

# Logistic Models ####
bl_cv_logit <- origami::cross_validate(
  cv_fun = cv_logit, folds = bl_folds1, data = baseline_1,
  reg_form = "beta_pos ~ AGE + MALE + APOE4_1 + APOE4_2 + RAVLT_immediate + Hippocampus + WholeBrain")

bl_cv_logit2 <- origami::cross_validate(
  cv_fun = cv_logit, folds = bl_folds2, data = baseline_2,
  reg_form = "beta_pos ~ AGE + MALE + APOE4_1 + APOE4_2 + RAVLT_immediate")

# Linear Models Stats ####
bl_lm_stats1 <- colMeans(dplyr::bind_rows(bl_cv_lm$c_stats))
bl_lm_stats2 <- colMeans(dplyr::bind_rows(bl_cv_lm2$c_stats))

# Logistic Model Stats ####
bl_log_stats1 <- colMeans(dplyr::bind_rows(bl_cv_logit$c_stats))
bl_log_stats2 <- colMeans(dplyr::bind_rows(bl_cv_logit2$c_stats))

# Combine Data ####
bl_summary <- dplyr::bind_rows(
        bl_lm_stats1, bl_lm_stats2, bl_log_stats1, bl_log_stats2)
```



```{r results='asis', echo=FALSE}
row.names(bl_summary) <- c(
        "Linear w/MRI", "Linear", "Logistic w/MRI", "Logistic")
colnames(bl_summary) <- c(
        "Misclass", "T Pos", "F Pos", "T Neg", "F Neg", 
        "DX Corr", "Pos AD", "Neg AD", "% Pos AD")

knitr::kable(bl_summary, caption = "Cross-Validation Results",
             row.names = TRUE, digits = 4, align = 'c')
```


A small subset of patients also had CSF measurements taken at other visits including 12-month and 24-month follow-ups, but the small sample size led us to omit these particular observations.

\newpage

## Second Stage Initial Fits

### Description

### Code and Output

## Discussion and Follow-up



