---
title: "Capstone Project: ADNI Data"
author: "Brian Collica, Ben Searchinger, Ryan Roggenkemper, James Koo"
date: "2/16/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data

### Access and Acquisition

The main source of our data will be DICOM format files of PET and MRI brain scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. For the purposes of this assignment, the data is coming from the Australian Imaging, Biomarkers, and Lifestyle (AIBL) database while we wait for final access approval from ADNI. Both databases are provided courtesy of the Laboratory of Neuro Imaging at the University of Southern California. It is unclear at this moment whether or not AIBL data will play a part in the final analysis, although this is a possibility we are exploring.

## Exploratory Data Analysis

### Downloading and Reading DICOM files

Much of the data is in DICOM format, a standardized file and metadata formatting system used in medical imaging. Other formats are also available such as NiFTI and ANALYZE, although we plan to restrict ourselves to the DICOM format.

There are many existing open-source software libraries in R and Python for reading and processing DICOM files. One such R package is `radtools` which is available on the Neuroconductor repository and also on GitHub. We have been able to successfully download PET brain scan images from AIBL and process them into R using the `radtools` package.

Below is an example work flow where we read in the entire 3D image from a directory containing 90 separate DICOM files, one for each image slice. Using the functions in `radtools`, we are able to inspect the dimensions of the data along with the metadata attributes. We can also transform the slices into a three dimensional array and inspect the results. `radtools` also facilitates viewing the actual image slices.

```{r radtools-install, eval=FALSE}
# Install Package
source("https://neuroconductor.org/neurocLite.R")
neuro_install('radtools', release = "stable", release_repo = "github")
```

```{r radtools-read, results='hold'}
library(radtools)

# Path to image directory
img_path <- "AIBL/10/summed.img__RSRCH_RAMLA3D-SUV/2006-10-17_13_53_08.0/I153055/"

# Read in 90 slices of PET image
PET <- read_dicom(img_path)

# Inspect image dimensions and number of slices
img_dimensions(PET)
num_slices(PET)
head(header_fields(PET))
```

```{r radtools-array, results='hold'}
img_array <- img_data_to_mat(PET)
dim(img_array)
img_array[65:70, 65:70, 65]
```

This single 6 x 6 matrix corresponds to the region outlined below in the image representing slice 65.

```{r image-slice, echo=FALSE, fig.width=4, fig.height=4, fig.align='center'}
view_slice(PET, slice = 65)
segments(x0=65, x1 = 70, y0 = 65, y1 = 65, col = "red")
segments(x0=65, x1 = 65, y0 = 65, y1 = 70, col = "red")
segments(x0=70, x1 = 70, y0 = 65, y1 = 70, col = "red")
segments(x0=65, x1 = 70, y0 = 70, y1 = 70, col = "red")
```

Some of the post-processed PET images use the NIfTI file format. Below is an
example using the Python library `NiBabel` to compare the images created from
two different levels of post-processing. Do not attempt to run this code in R,
as it will likely cause a fatal error. Instead just copy and paste the code
into a Python interpreter, and make sure you have the necessary libraries 
installed.

```{python, eval = FALSE}
##DO NOT RUN IN R##
import nibabel as nib
import os
import matplotlib.pyplot as plt

# somewhat unnecessary with the file structure inside this repo
dir = 'ADNI_test_files'
img1 = nib.load(dir + '\\' + os.listdir(dir)[0])
img2 = nib.load(dir + '\\' + os.listdir(dir)[1])

# load in the image arrays
img1_data = img1.get_fdata()
img2_data = img2.get_fdata()

# code borrowed from here:
# https://nipy.org/nibabel/coordinate_systems.html#introducing-someone
def show_slices(slices):
    """ Function to display row of image slices """
    fig, axes = plt.subplots(1, len(slices), figsize = (20, 10))
    for i, slice in enumerate(slices):
        axes[i].imshow(slice.T, origin="lower")
        
slice_0 = img1_data[26, :, :]
slice_1 = img1_data[:, 30, :]
slice_2 = img1_data[:, :, 16]

slice_3 = img2_data[26, :, :]
slice_4 = img2_data[:, 30, :]
slice_5 = img2_data[:, :, 16]
show_slices([slice_0, slice_1, slice_2, slice_3, slice_4, slice_5])

```
![Sample NIfTI PET Plots](ADNI_test_files/test.jpg)

## Project Outline and Analysis Plan

### State of Current Research

Many papers have been published addressing the challenges associated with Alzheimer's research and using neuroimaging data. There is an overall lack of consensus regarding standardization of metrics and also which data and attributes are of importance. Additionally, there is much heterogeneity in the analysis approach employed by researchers with everything ranging from multiple linear regression models to deep learning with 3D convolutional neural networks.

Below are a few publications of interest:

-   *Tau pathology in cognitively normal older adults*

    -   <https://doi.org/10.1016/j.dadm.2019.07.007>

-   *Robust automated computational approach for classifying frontotemporal neurodegeneration: Multimodal/multicenter neuroimaging*

    -   <https://doi.org/10.1016/j.dadm.2019.06.002>
    
-   *Practical algorithms for amyloid $\beta$ probability in subjective or mild cognitive impairment*

    -   <https://doi.org/10.1016/j.dadm.2019.09.001>

-   *Added value of amyloid PET in individualized risk predictions for MCI patients* 

    -   <https://doi.org/10.1016/j.dadm.2019.04.011>

-   *Machine learning framework for early MRI-based Alzheimer's conversion prediction in MCI subjects*

    -   <http://dx.doi.org/10.1016/j.neuroimage.2014.10.002>

-   *Deep learning detection of informative features in tau PET for Alzheimer's disease classification* 

    -   <https://doi.org/10.1186/s12859-020-03848-0>

### Question of Interest

The specific question of interest being addressed in this project is: can we combine the approaches and metrics from several recent studies into a general, multi-modal framework for identifying and tracking Alzheimer's Disease?

### Analysis Approach

We plan to approach this question by first identifying a few main studies of interest. Then we plan to compare the various analytic approaches, including how each study processed their images, in order to come up with a method that can generalize across many platforms, image types, and patient characteristics.

Since this is a multi-modal approach, we hope to utilize various statistical methods where appropriate including, but not limited to, linear and logistic regression, support vector machine classifiers, and convolutional neural networks. Given the high dimensional nature of the data, we also plan to utilize dimension reduction techniques such as regularization or principal components analysis in order to facilitate noise reduction and aide in feature selection.

Breaking the overall analysis into different steps means that we can utilize different software for various tasks where appropriate. For example, one part of the model can be fit in R while another part can be fit in Python. We also plan to leverage parallel processing when fitting and validating our model. To facilitate this, we're seeking access to the campus Savio computing cluster and have also reached out to AWS for access to free research computing credits.

### Project Roadmap

The project can be broken up into the following main steps:

+-------------+----------+------------------------------------------------------------------------------------------------------+
| Step Number | Due Date | Description                                                                                          |
+=============+==========+======================================================================================================+
| 1           | 2/16     | Preliminary Plan, EDA, and Project Description                                                       |
+-------------+----------+------------------------------------------------------------------------------------------------------+
| 2           | 2/23     | Define the exact data to be used for analysis and have it downloaded                                 |
+-------------+----------+------------------------------------------------------------------------------------------------------+
| 3           | 3/2      | Have pipelines built for pre-processing images in R or Python with FreeSurfer & EDA Presentation Due |
+-------------+----------+------------------------------------------------------------------------------------------------------+
| 4           | 3/16     | Have all images processed and ready to be fit into various models                                    |
+-------------+----------+------------------------------------------------------------------------------------------------------+
| 5           | 3/30     | Evaluate fit of preliminary model presentation due                                                   |
+-------------+----------+------------------------------------------------------------------------------------------------------+
| 6           | 4/13     | Finish and evaluate secondary model fit                                                              |
+-------------+----------+------------------------------------------------------------------------------------------------------+
| 7           | 4/27     | Have final results ready to go and finish details of presentation                                    |
+-------------+----------+------------------------------------------------------------------------------------------------------+
| 8           | 5/4      | Final presentations due                                                                              |
+-------------+----------+------------------------------------------------------------------------------------------------------+

While each step has a specified target completion date, this is flexible depending on the unknown complications we will encounter, such as still not having access to the ADNI data despite numerous attempts to reach out to the appropriate parties in charge.



